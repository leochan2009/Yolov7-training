{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f278c995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\endo\\anaconda3\\envs\\yolov7_custon\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5cd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu113\n",
      "0.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0e9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3722e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60e9d0b-c375-423f-8999-d19841e98946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc8ec2d-144a-4b7c-96eb-e8f5c9021315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43c945-d45c-4b58-895f-9fd76775dc36",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebd293-e06f-4fa5-a0a0-0fe93a0d0b80",
   "metadata": {},
   "source": [
    "First, let's take a look at how to load our dataset in the format that Yolov7 expects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cae8d4",
   "metadata": {},
   "source": [
    "## Selecting a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbfefe-6c3c-4f13-b6a8-9b7230d94669",
   "metadata": {},
   "source": [
    "Throughout this article, we shall use the [Kaggle cars object detection dataset](https://www.kaggle.com/datasets/sshikamaru/car-object-detection); however, as our aim is to demonstrate how Yolov7 can be applied to any problem, this is really the least important part of this work. Additionally, as the images are quite similar to COCO, it will enable us to experiment with a pretrained model before we do any training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984e66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90dabcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/papilla\"\n",
    "data_path = Path(data_path)\n",
    "images_path = data_path / \"all_images\"\n",
    "annotations_file_path = data_path / \"annotations_final.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a95386",
   "metadata": {},
   "source": [
    "The annotations for this dataset are in the form of a .csv file, which associates the image name with the corresponding annotations; where each row represents one bounding box. Whilst there are around 1000 images in the training set, only those with annotations are included in this file. \n",
    "\n",
    "We can view the format of this by loading it into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87fa5ee5-7bf3-4ba6-8f9a-2678418665a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(annotations_file_path).drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d641af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class_name</th>\n",
       "      <th>has_annotation</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0104G2021-03-24-15h05m37s184.png</td>\n",
       "      <td>634.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0104G2021-03-24-15h05m38s864.png</td>\n",
       "      <td>616.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104G2021-03-24-15h05m33s582.png</td>\n",
       "      <td>689.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226274</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0104G2021-03-24-15h05m35s099.png</td>\n",
       "      <td>718.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0104G2021-03-24-15h05m32s249.png</td>\n",
       "      <td>703.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>00953G00827.png</td>\n",
       "      <td>801.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>00953G00822.png</td>\n",
       "      <td>601.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>00953G00829.png</td>\n",
       "      <td>856.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>00953G00819.png</td>\n",
       "      <td>649.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>00953G00828.png</td>\n",
       "      <td>890.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image   xmin   ymin    xmax   ymax  \\\n",
       "0     0104G2021-03-24-15h05m37s184.png  634.0  173.0  1068.0  576.0   \n",
       "1     0104G2021-03-24-15h05m38s864.png  616.0  177.0  1068.0  580.0   \n",
       "2     0104G2021-03-24-15h05m33s582.png  689.0  131.0  1107.0  494.0   \n",
       "3     0104G2021-03-24-15h05m35s099.png  718.0  120.0  1056.0  481.0   \n",
       "4     0104G2021-03-24-15h05m32s249.png  703.0  126.0  1122.0  497.0   \n",
       "...                                ...    ...    ...     ...    ...   \n",
       "1034                   00953G00827.png  801.0   76.0  1119.0  324.0   \n",
       "1035                   00953G00822.png  601.0   59.0  1025.0  318.0   \n",
       "1036                   00953G00829.png  856.0  102.0  1118.0  298.0   \n",
       "1037                   00953G00819.png  649.0   58.0  1024.0  244.0   \n",
       "1038                   00953G00828.png  890.0   52.0  1116.0  198.0   \n",
       "\n",
       "     class_name  has_annotation  image_id  class_id  \n",
       "0       papilla            True    226272       0.0  \n",
       "1       papilla            True    226273       0.0  \n",
       "2       papilla            True    226274       0.0  \n",
       "3       papilla            True    226275       0.0  \n",
       "4       papilla            True    226276       0.0  \n",
       "...         ...             ...       ...       ...  \n",
       "1034    papilla            True    227100       0.0  \n",
       "1035    papilla            True    227101       0.0  \n",
       "1036    papilla            True    227102       0.0  \n",
       "1037    papilla            True    227104       0.0  \n",
       "1038    papilla            True    227103       0.0  \n",
       "\n",
       "[1039 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1c2a8-0115-4c47-8eec-997f5f9e34e6",
   "metadata": {},
   "source": [
    "As it is not usually the case that all images in our dataset contain instances of the objects that we are trying to detect, we would also like to include some images that do not contain cars. To do this, we can define a function to load the annotations which also includes 100 'negative' images. Additionally, as the designated test set is unlabelled, let's randomly take 20% of these images to use as our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9149fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def load_cars_df(annotations_file_path, images_path):\n",
    "    # all_images = sorted(set([p.parts[-1] for p in images_path.iterdir()]))\n",
    "    image_id_to_image = {i: im for i, im in zip(df.image_id, df.image)}\n",
    "    image_to_image_id = {v: k for k, v, in image_id_to_image.items()}\n",
    "    \n",
    "    class_id_to_label = dict(\n",
    "        enumerate(df.query(\"has_annotation == True\").class_name.unique())\n",
    "    )\n",
    "    class_label_to_id = {v: k for k, v in class_id_to_label.items()}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # first, split into X_train, X_valid_test, y_train, y_valid_test\n",
    "    # `test_size=0.3` split into 70% and 30%\n",
    "    train_df, valid_test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "    # second, split into X_valid, X_test, y_valid, y_test\n",
    "    # `test_size=0.5` split into 50% and 50%. The original data set is 30%,\n",
    "    # so, it will split into 15% equally.\n",
    "    valid_df, test_df = train_test_split(valid_test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "    \n",
    "    lookups = {\n",
    "        \"image_id_to_image\": image_id_to_image,\n",
    "        \"image_to_image_id\": image_to_image_id,\n",
    "        \"class_id_to_label\": class_id_to_label,\n",
    "        \"class_label_to_id\": class_label_to_id,\n",
    "    }\n",
    "    return train_df, valid_df, test_df, lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f2f4e-983b-4b70-b289-2beb8059d21a",
   "metadata": {},
   "source": [
    "We can now use this function to load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c95ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df, lookups = load_cars_df(annotations_file_path, images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045ee0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class_name</th>\n",
       "      <th>has_annotation</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0104G2021-03-24-15h10m49s388.png</td>\n",
       "      <td>561.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>00953G00709.png</td>\n",
       "      <td>701.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0104G09661.png</td>\n",
       "      <td>580.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226522</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0305G2021-03-24-15h22m13s740.png</td>\n",
       "      <td>551.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>00011.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>background</td>\n",
       "      <td>False</td>\n",
       "      <td>243877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                image   xmin   ymin    xmax   ymax  \\\n",
       "118  0104G2021-03-24-15h10m49s388.png  561.0  320.0   900.0  581.0   \n",
       "914                   00953G00709.png  701.0  105.0  1004.0  564.0   \n",
       "250                    0104G09661.png  580.0   48.0  1112.0  526.0   \n",
       "390  0305G2021-03-24-15h22m13s740.png  551.0  262.0  1118.0  680.0   \n",
       "827                         00011.jpg    NaN    NaN     NaN    NaN   \n",
       "\n",
       "     class_name  has_annotation  image_id  class_id  \n",
       "118     papilla            True    226389       0.0  \n",
       "914     papilla            True    226984       0.0  \n",
       "250     papilla            True    226522       0.0  \n",
       "390     papilla            True    226662       0.0  \n",
       "827  background           False    243877       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d545b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class_name</th>\n",
       "      <th>has_annotation</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0104G2021-03-24-14h59m28s244.png</td>\n",
       "      <td>768.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0104G2021-03-24-15h12m07s678.png</td>\n",
       "      <td>772.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226411</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0104G2021-03-24-14h55m23s665.png</td>\n",
       "      <td>642.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>00953G00795.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>background</td>\n",
       "      <td>False</td>\n",
       "      <td>227070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0305G2021-03-24-15h35m27s941.png</td>\n",
       "      <td>604.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>226810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image   xmin   ymin    xmax   ymax  \\\n",
       "760   0104G2021-03-24-14h59m28s244.png  768.0  154.0   978.0  532.0   \n",
       "139   0104G2021-03-24-15h12m07s678.png  772.0   41.0   979.0  271.0   \n",
       "688   0104G2021-03-24-14h55m23s665.png  642.0  189.0   920.0  457.0   \n",
       "1004                   00953G00795.png    NaN    NaN     NaN    NaN   \n",
       "538   0305G2021-03-24-15h35m27s941.png  604.0   44.0  1120.0  336.0   \n",
       "\n",
       "      class_name  has_annotation  image_id  class_id  \n",
       "760      papilla            True    227236       0.0  \n",
       "139      papilla            True    226411       0.0  \n",
       "688      papilla            True    227164       0.0  \n",
       "1004  background           False    227070       NaN  \n",
       "538      papilla            True    226810       0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8fdbb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class_name</th>\n",
       "      <th>has_annotation</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0305G2021-03-24-15h30m45s167.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>background</td>\n",
       "      <td>False</td>\n",
       "      <td>226757</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>00953G00827.png</td>\n",
       "      <td>801.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0104G2021-03-24-14h53m26s950.png</td>\n",
       "      <td>705.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0104G2021-03-24-14h54m21s113.png</td>\n",
       "      <td>624.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227141</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>00953G00829.png</td>\n",
       "      <td>856.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>papilla</td>\n",
       "      <td>True</td>\n",
       "      <td>227102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image   xmin   ymin    xmax   ymax  \\\n",
       "485   0305G2021-03-24-15h30m45s167.png    NaN    NaN     NaN    NaN   \n",
       "1034                   00953G00827.png  801.0   76.0  1119.0  324.0   \n",
       "643   0104G2021-03-24-14h53m26s950.png  705.0  456.0   983.0  630.0   \n",
       "665   0104G2021-03-24-14h54m21s113.png  624.0  160.0  1073.0  541.0   \n",
       "1036                   00953G00829.png  856.0  102.0  1118.0  298.0   \n",
       "\n",
       "      class_name  has_annotation  image_id  class_id  \n",
       "485   background           False    226757       NaN  \n",
       "1034     papilla            True    227100       0.0  \n",
       "643      papilla            True    227119       0.0  \n",
       "665      papilla            True    227141       0.0  \n",
       "1036     papilla            True    227102       0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14bbd01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727 156 156\n"
     ]
    }
   ],
   "source": [
    "print(train_df.image.nunique(), valid_df.image.nunique(), test_df.image.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9957044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Validation into Val and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55829-04a3-4a64-8f4b-15561c1485dd",
   "metadata": {},
   "source": [
    "To make it easier to associate predictions with an image, we have assigned each image a unique id; in this case it is just an incrementing integer count. Additionally, we have added an integer value to represent the classes that we want to detect, which is a single class - 'car' - in this case.\n",
    "\n",
    "Generally, object detection models reserve `0` as the background class, so class labels should start from `1`. This is **not** the case for Yolov7, so we start our class encoding from `0`. For images that do not contain a car, we do not require a class id. We can confirm that this is the case by inspecting the lookups returned by our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163741fe-fa70-4b75-9e00-0acf9772250d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_id_to_image', 'image_to_image_id', 'class_id_to_label', 'class_label_to_id'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833892c8-a792-461a-b73e-506a71f5c9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'papilla': 0}, {0: 'papilla'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups['class_label_to_id'], lookups['class_id_to_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a5bbf-55af-4be7-beff-c35168264306",
   "metadata": {},
   "source": [
    "Finally, let's see the number of images in each class for our training and validation sets. As an image can have multiple annotations, we need to make sure that we account for this when calculating our counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba3be48e-aa09-482a-b9e5-9ea99a62da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. annotated images in training set: 662\n",
      "Num. Background images in training set: 65\n",
      "Total Num. images in training set: 727\n",
      "------------\n",
      "Num. annotated images in validation set: 138\n",
      "Num. Background images in validation set: 18\n",
      "Total Num. images in validation set: 156\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num. annotated images in training set: {len(train_df.query('has_annotation == True').image.unique())}\")\n",
    "print(f\"Num. Background images in training set: {len(train_df.query('has_annotation == False').image.unique())}\")\n",
    "print(f\"Total Num. images in training set: {len(train_df.image.unique())}\")\n",
    "print('------------')\n",
    "\n",
    "print(f\"Num. annotated images in validation set: {len(valid_df.query('has_annotation == True').image.unique())}\")\n",
    "print(f\"Num. Background images in validation set: {len(valid_df.query('has_annotation == False').image.unique())}\")\n",
    "print(f\"Total Num. images in validation set: {len(valid_df.image.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ffa5b8",
   "metadata": {},
   "source": [
    "## Create a Dataset Adaptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d1d56",
   "metadata": {},
   "source": [
    "Usually, at this point, we would create a PyTorch dataset specific to the model that we shall be training. \n",
    "\n",
    "However, we often use the pattern of first creating a dataset 'adaptor' class, with the sole responsibility of wrapping the underlying data sources and loading this appropriately. This way, we can easily switch out adaptors when using different datasets, without changing any pre-processing logic which is specific to the model that we are training.\n",
    "\n",
    "Therefore, let’s focus for now on creating a `CarsDatasetAdaptor` class, which converts the specific raw dataset format into an image and corresponding annotations. Additionally, let's load the image id that we assigned, as well as the height and width of our image, as they may be useful to us later on.\n",
    "\n",
    "An implementation of this is presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09cb9e74-6a8c-4bb3-88da-adc70ab8db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_accelerated:Setting random seeds\n"
     ]
    }
   ],
   "source": [
    "from train_cars import CarsDatasetAdaptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13850f79-55ed-4f32-b1f8-cd8e4cf8b2cb",
   "metadata": {},
   "source": [
    "Notice that, for our background images, we are just returning an empty array for our bounding boxes and class ids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e033c-58d0-4fb7-a365-c266918eb481",
   "metadata": {},
   "source": [
    "Using this, we can confirm that the length of our dataset is the same as the total number of training images that we calculated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f825aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CarsDatasetAdaptor(images_path, train_df)\n",
    "valid_ds= CarsDatasetAdaptor(images_path, valid_df)\n",
    "test_ds= CarsDatasetAdaptor(images_path, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd22bea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<train_cars.CarsDatasetAdaptor at 0x2100ac20e20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93645547-98a9-4f89-baf4-0ec8bdb7f2c8",
   "metadata": {},
   "source": [
    "Now, we can use this to visualise some of our images, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4a43a0d-3c4f-4ab7-883e-faaf599309a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov7.plotting import show_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ba518-4b35-4ca6-b279-fccac0956ee4",
   "metadata": {},
   "source": [
    "Let's wrap our data adaptor using this dataset and inspect some of the outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894d9c4",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf1bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov7.dataset import Yolov7Dataset\n",
    "from yolov7.dataset import create_yolov7_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e17b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_size = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e502980",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yds = Yolov7Dataset(train_ds, transforms=create_yolov7_transforms(image_size=(target_image_size, target_image_size)))\n",
    "eval_yds= Yolov7Dataset(valid_ds, transforms=create_yolov7_transforms(image_size=(target_image_size, target_image_size)))\n",
    "test_yds= Yolov7Dataset(test_ds, transforms=create_yolov7_transforms(image_size=(target_image_size, target_image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c621dbe-d72a-4a4b-a607-ebd3f7210a69",
   "metadata": {},
   "source": [
    "Using these transforms, we can see that our image has been resized to our target size and padding has been applied. The reason that padding is used is so that we can maintain the aspect ratio of the objects in the images, but have a common size for images in our dataset; enabling us to batch them efficiently!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd71b8",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1858ebc-fd61-4a64-9e53-127bf52d1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov7.trainer import Yolov7Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de303f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\endo\\Desktop\\Yolov7-training-main\\Yolov7-training-main\\examples\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\endo\\Desktop\\Yolov7-training-main\\Yolov7-training-main\\examples\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "598f7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from func_to_script import script\n",
    "from PIL import Image\n",
    "from pytorch_accelerated.callbacks import (\n",
    "    EarlyStoppingCallback,\n",
    "    SaveBestModelCallback,\n",
    "    get_default_callbacks,\n",
    ")\n",
    "from pytorch_accelerated.schedulers import CosineLrScheduler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from yolov7 import create_yolov7_model\n",
    "from yolov7.dataset import Yolov7Dataset, create_yolov7_transforms, yolov7_collate_fn\n",
    "from yolov7.evaluation import CalculateMeanAveragePrecisionCallback\n",
    "from yolov7.loss_factory import create_yolov7_loss\n",
    "from yolov7.trainer import Yolov7Trainer, filter_eval_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1ed4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 555/566 items from https://github.com/Chris-hughes10/Yolov7-training/releases/download/0.1.0/yolov7_training_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Defining model \n",
    "best_model = create_yolov7_model('yolov7', num_classes=1)\n",
    "best_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "129b2eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Weights\n",
    "best_model_path= 'C:\\\\Users\\\\endo\\\\Desktop\\\\Yolov7-training-main\\\\Yolov7-training-main\\\\examples\\\\train_scratch_best_model2.pt'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "best_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce512a",
   "metadata": {},
   "source": [
    "### Running inference on test set and evaluating the performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f030f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format= \"corners\"):\n",
    "    # (N,4): N--number of bboxes\n",
    "    # boxes_labels shape is (N,4)\n",
    "    \n",
    "    '''Calculates intersection over union\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "        '''       \n",
    "    if box_format == \"corners\":\n",
    "        \n",
    "        #Converting cx,cy,w,h (center_x, center_y,w,h) into (xmin, ymin, xmax, ymax)\n",
    "        \n",
    "#         print(boxes_labels)\n",
    "#         print(boxes_preds)\n",
    "        \n",
    "        center_x= boxes_labels[..., 0:1]\n",
    "        center_y = boxes_labels[..., 1:2] \n",
    "        width = boxes_labels[..., 2:3] \n",
    "        height= boxes_labels[..., 3:4] \n",
    "        new_boxes_labels = torch.zeros_like(boxes_labels) # Initializing the tensor\n",
    "\n",
    "        new_boxes_labels[..., 0:1]= center_x - (width / 2)\n",
    "        new_boxes_labels[..., 1:2]= center_y - (height / 2)\n",
    "        new_boxes_labels[..., 2:3]= center_x + (width / 2)\n",
    "        new_boxes_labels[..., 3:4]= center_y + (height / 2)        \n",
    "        \n",
    "        \n",
    "        pred_xmin= boxes_preds[..., 0:1]\n",
    "        pred_ymin= boxes_preds[..., 1:2]\n",
    "        pred_xmax= boxes_preds[..., 2:3]\n",
    "        pred_ymax= boxes_preds[..., 3:4]\n",
    "\n",
    "        label_xmin= new_boxes_labels[..., 0:1]\n",
    "        label_ymin= new_boxes_labels[..., 1:2]\n",
    "        label_xmax= new_boxes_labels[..., 2:3]\n",
    "        label_ymax= new_boxes_labels[..., 3:4]\n",
    "\n",
    "    inter_area = max(0, min(pred_xmax, label_xmax) - max(pred_xmin, label_xmin)) * \\\n",
    "             max(0, min(pred_ymax, label_ymax) - max(pred_ymin, label_ymin))\n",
    "\n",
    "    pred_area = (pred_xmax - pred_xmin) * (pred_ymax - pred_ymin)\n",
    "    label_area = (label_xmax - label_xmin) * (label_ymax - label_ymin)\n",
    "    union_area = pred_area + label_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "    conf= boxes_preds[...,4:5]\n",
    "    return iou, conf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81629d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\endo\\anaconda3\\envs\\yolov7_custon\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Validation Image\n",
    "df_list=[]\n",
    "iou_thres= 0.5\n",
    "for i in range(len(test_df)):\n",
    "    \n",
    "    # Taking a test image\n",
    "    image_tensor, labels, image_id, image_size = test_yds[i]\n",
    "    boxes_labels = labels[:, 2:]\n",
    "    boxes_labels[:, [0, 2]] *= target_image_size\n",
    "    boxes_labels[:, [1, 3]] *= target_image_size\n",
    "    \n",
    "    # Predicting \n",
    "    with torch.no_grad():\n",
    "        model_outputs = best_model(image_tensor[None])\n",
    "        preds = best_model.postprocess(model_outputs, conf_thres=0., multiple_labels_per_box=False)  \n",
    "        \n",
    "    # This has the bounding boxes with confidence and class label\n",
    "    nms_predictions = filter_eval_predictions(preds, confidence_threshold=0.1)\n",
    "    data= {'image_id':[],'gt_flag':[],'pd_flag':[], 'confidence':[], 'iou':[], 'tp':[], 'fp':[], 'fn':[], 'tn':[]}\n",
    "    \n",
    "    \n",
    "    # Chec if the Ground Truth Bbox is available:\n",
    "    if boxes_labels.numel()==0:\n",
    "        # Now check if Predicted Bounding boxes are zero or any got predicted:\n",
    "        if nms_predictions[0].numel()==0:\n",
    "#             print(\" We dont care about this case\")\n",
    "            data['image_id']= image_id.tolist()\n",
    "            data['gt_flag'].append(1)\n",
    "            data['pd_flag'].append(1)\n",
    "            data['confidence'].append(np.nan)\n",
    "            data['iou'].append(np.nan)\n",
    "            data['tp'].append(np.nan)\n",
    "            data['fn'].append(np.nan)\n",
    "            data['fp'].append(np.nan)\n",
    "            data['tn'].append(1)\n",
    "        elif nms_predictions[0].numel()!=0:\n",
    "            data['image_id']= image_id.tolist()\n",
    "            data['gt_flag'].append(1)\n",
    "            data['pd_flag'].append(0)\n",
    "            data['confidence'].append(np.nan)\n",
    "            data['iou'].append(np.nan)\n",
    "            data['tp'].append(np.nan)\n",
    "            data['fn'].append(np.nan)\n",
    "            data['fp'].append(1)\n",
    "            data['tn'].append(np.nan)\n",
    "    # this is when the ground truth bounding box is available:\n",
    "    else:\n",
    "        # Now we chck if the prediction are done or not:\n",
    "        # Checking if there are no predictions:\n",
    "        if nms_predictions[0].numel()==0:\n",
    "            data['image_id']= image_id.tolist()\n",
    "            data['gt_flag'].append(0)\n",
    "            data['pd_flag'].append(1)\n",
    "            data['confidence'].append(np.nan)\n",
    "            data['iou'].append(np.nan)\n",
    "            data['tp'].append(np.nan)\n",
    "            data['fn'].append(1)\n",
    "            data['fp'].append(np.nan)\n",
    "            data['tn'].append(np.nan)\n",
    "        # Checking ig the prediction is done\n",
    "        elif nms_predictions[0].numel()!=0:\n",
    "            # In this case we check for IOU:\n",
    "            # First we check of the number of predictions are 1 or more:\n",
    "#             my_iou_list=[]\n",
    "#             confidence= []\n",
    "            \n",
    "            if len(nms_predictions[0])>1:\n",
    "                for j in range(len(nms_predictions[0])):\n",
    "                    my_iou, conf= intersection_over_union(nms_predictions[0][j], boxes_labels, box_format= \"corners\")\n",
    "#                     print(conf)\n",
    "                    if my_iou> iou_thres:\n",
    "                        data['image_id']= image_id.tolist()\n",
    "                        data['gt_flag'].append(0)\n",
    "                        data['pd_flag'].append(0)\n",
    "                        data['confidence'].append(conf[0].tolist())\n",
    "                        data['iou'].append(my_iou[0][0].tolist())\n",
    "                        data['tp'].append(1)\n",
    "                        data['fn'].append(np.nan)\n",
    "                        data['fp'].append(np.nan)\n",
    "                        data['tn'].append(np.nan)\n",
    "                    else:\n",
    "                        data['image_id']= image_id.tolist()\n",
    "                        data['gt_flag'].append(0)\n",
    "                        data['pd_flag'].append(0)\n",
    "                        data['confidence'].append(conf[0].tolist())\n",
    "                        data['iou'].append(my_iou[0][0].tolist())\n",
    "                        data['tp'].append(np.nan)\n",
    "                        data['fn'].append(np.nan)\n",
    "                        data['fp'].append(1)\n",
    "                        data['tn'].append(np.nan)\n",
    "                        \n",
    "#                     my_iou_list.append(my_iou)\n",
    "#                     confidence.append(conf)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                my_iou, conf= intersection_over_union(nms_predictions[0], boxes_labels, box_format= \"corners\")\n",
    "                \n",
    "#                 print(conf)\n",
    "                \n",
    "                if my_iou> iou_thres:\n",
    "                    data['image_id']= image_id.tolist()\n",
    "                    data['gt_flag'].append(0)\n",
    "                    data['pd_flag'].append(0)\n",
    "                    data['confidence'].append(conf[0][0].tolist())\n",
    "                    data['iou'].append(my_iou[0][0].tolist())\n",
    "                    data['tp'].append(1)\n",
    "                    data['fn'].append(np.nan)\n",
    "                    data['fp'].append(np.nan)\n",
    "                    data['tn'].append(np.nan)\n",
    "                else:\n",
    "                    data['image_id']= image_id.tolist()\n",
    "                    data['gt_flag'].append(0)\n",
    "                    data['pd_flag'].append(0)\n",
    "                    data['confidence'].append(conf[0][0].tolist())\n",
    "                    data['iou'].append(my_iou[0][0].tolist())\n",
    "                    data['tp'].append(np.nan)\n",
    "                    data['fn'].append(np.nan)\n",
    "                    data['fp'].append(1)\n",
    "                    data['tn'].append(np.nan)\n",
    "#                 my_iou_list.append(my_iou)\n",
    "#                 confidence.append(conf)\n",
    "\n",
    "    df= pd.DataFrame(data)\n",
    "#     display(df)\n",
    "    df_list.append(df)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e5e9938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 226720,\n",
       " 'gt_flag': [1],\n",
       " 'pd_flag': [0],\n",
       " 'confidence': [nan],\n",
       " 'iou': [nan],\n",
       " 'tp': [nan],\n",
       " 'fp': [1],\n",
       " 'fn': [nan],\n",
       " 'tn': [nan]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9a1b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df= pd.concat(df_list).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff75f3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.image_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb930a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.image_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "769446f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>gt_flag</th>\n",
       "      <th>pd_flag</th>\n",
       "      <th>confidence</th>\n",
       "      <th>iou</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226757</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766513</td>\n",
       "      <td>0.623717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.362895</td>\n",
       "      <td>0.392403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124941</td>\n",
       "      <td>0.505912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>226623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124448</td>\n",
       "      <td>0.658996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>226339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891160</td>\n",
       "      <td>0.731925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>226339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656981</td>\n",
       "      <td>0.684073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>226339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203273</td>\n",
       "      <td>0.494108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>226720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  gt_flag  pd_flag  confidence       iou   tp   fp   fn   tn\n",
       "0      226757        1        1         NaN       NaN  NaN  NaN  NaN  1.0\n",
       "1      227100        0        1         NaN       NaN  NaN  NaN  1.0  NaN\n",
       "2      227119        0        0    0.766513  0.623717  1.0  NaN  NaN  NaN\n",
       "3      227119        0        0    0.362895  0.392403  NaN  1.0  NaN  NaN\n",
       "4      227119        0        0    0.124941  0.505912  1.0  NaN  NaN  NaN\n",
       "..        ...      ...      ...         ...       ...  ...  ...  ...  ...\n",
       "338    226623        0        0    0.124448  0.658996  1.0  NaN  NaN  NaN\n",
       "339    226339        0        0    0.891160  0.731925  1.0  NaN  NaN  NaN\n",
       "340    226339        0        0    0.656981  0.684073  1.0  NaN  NaN  NaN\n",
       "341    226339        0        0    0.203273  0.494108  NaN  1.0  NaN  NaN\n",
       "342    226720        1        0         NaN       NaN  NaN  1.0  NaN  NaN\n",
       "\n",
       "[343 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "855ec8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sort= final_df.sort_values('confidence', ascending=False).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68f7b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>gt_flag</th>\n",
       "      <th>pd_flag</th>\n",
       "      <th>confidence</th>\n",
       "      <th>iou</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970579</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947109</td>\n",
       "      <td>0.880324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945899</td>\n",
       "      <td>0.844908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>0.893873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941632</td>\n",
       "      <td>0.841578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  gt_flag  pd_flag  confidence       iou   tp  fp  fn  tn\n",
       "0    226376        0        0    0.970579  0.931755  1.0 NaN NaN NaN\n",
       "1    227132        0        0    0.947109  0.880324  1.0 NaN NaN NaN\n",
       "2    226372        0        0    0.945899  0.844908  1.0 NaN NaN NaN\n",
       "3    226653        0        0    0.945196  0.893873  1.0 NaN NaN NaN\n",
       "4    227279        0        0    0.941632  0.841578  1.0 NaN NaN NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "546a3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sort['tp_fp_fn'] = np.where((final_df_sort['tp'] ==1.0) , 'TP', \n",
    "                        np.where((final_df_sort['fp'] ==1.0) , 'FP', \n",
    "                                 np.where((final_df_sort['tn'] ==1.0) , 'TN',\n",
    "                                          np.where((final_df_sort['fn'] ==1.0) , 'FN', np.nan))))\n",
    "\n",
    "###############################################\n",
    "\n",
    "final_df_sort['tp'] = final_df_sort['tp_fp_fn'].apply(lambda x: 1 if x == 'TP' else 0)\n",
    "final_df_sort['fp'] = final_df_sort['tp_fp_fn'].apply(lambda x: 1 if x == 'FP' else 0)\n",
    "final_df_sort['fn'] = final_df_sort['tp_fp_fn'].apply(lambda x: 1 if x == 'FN' else 0)\n",
    "final_df_sort['tn'] = final_df_sort['tp_fp_fn'].apply(lambda x: 1 if x == 'TN' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00fc30f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>gt_flag</th>\n",
       "      <th>pd_flag</th>\n",
       "      <th>confidence</th>\n",
       "      <th>iou</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp_fp_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970579</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947109</td>\n",
       "      <td>0.880324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945899</td>\n",
       "      <td>0.844908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>0.893873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941632</td>\n",
       "      <td>0.841578</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  gt_flag  pd_flag  confidence       iou  tp  fp  fn  tn tp_fp_fn\n",
       "0    226376        0        0    0.970579  0.931755   1   0   0   0       TP\n",
       "1    227132        0        0    0.947109  0.880324   1   0   0   0       TP\n",
       "2    226372        0        0    0.945899  0.844908   1   0   0   0       TP\n",
       "3    226653        0        0    0.945196  0.893873   1   0   0   0       TP\n",
       "4    227279        0        0    0.941632  0.841578   1   0   0   0       TP"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4c60c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "tp = np.cumsum(final_df_sort['tp_fp_fn'] == 'TP')\n",
    "fp = np.cumsum(final_df_sort['tp_fp_fn'] == 'FP')\n",
    "fn = np.sum(final_df_sort['tp_fp_fn'] == 'FN')\n",
    "\n",
    "# Calculate precision and recall at each threshold\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "final_df_sort['precision']= precision\n",
    "final_df_sort['recall']= recall\n",
    "auc_pr = auc(final_df_sort['recall'], final_df_sort['precision'])\n",
    "\n",
    "# Or can use the:\n",
    "auc= torch.trapz(torch.tensor(final_df_sort['precision'].values), torch.tensor(final_df_sort['recall'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "997b5ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8588029215974673, tensor(0.8588, dtype=torch.float64))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pr, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7ecb361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>gt_flag</th>\n",
       "      <th>pd_flag</th>\n",
       "      <th>confidence</th>\n",
       "      <th>iou</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp_fp_fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970579</td>\n",
       "      <td>0.931755</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947109</td>\n",
       "      <td>0.880324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945899</td>\n",
       "      <td>0.844908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>0.893873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941632</td>\n",
       "      <td>0.841578</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>226973</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.701863</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>226863</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.699690</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>226614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FN</td>\n",
       "      <td>0.699690</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>243879</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TN</td>\n",
       "      <td>0.699690</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>226720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP</td>\n",
       "      <td>0.697531</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  gt_flag  pd_flag  confidence       iou  tp  fp  fn  tn  \\\n",
       "0      226376        0        0    0.970579  0.931755   1   0   0   0   \n",
       "1      227132        0        0    0.947109  0.880324   1   0   0   0   \n",
       "2      226372        0        0    0.945899  0.844908   1   0   0   0   \n",
       "3      226653        0        0    0.945196  0.893873   1   0   0   0   \n",
       "4      227279        0        0    0.941632  0.841578   1   0   0   0   \n",
       "..        ...      ...      ...         ...       ...  ..  ..  ..  ..   \n",
       "338    226973        0        1         NaN       NaN   0   0   1   0   \n",
       "339    226863        1        0         NaN       NaN   0   1   0   0   \n",
       "340    226614        0        1         NaN       NaN   0   0   1   0   \n",
       "341    243879        1        1         NaN       NaN   0   0   0   1   \n",
       "342    226720        1        0         NaN       NaN   0   1   0   0   \n",
       "\n",
       "    tp_fp_fn  precision    recall  \n",
       "0         TP   1.000000  0.083333  \n",
       "1         TP   1.000000  0.153846  \n",
       "2         TP   1.000000  0.214286  \n",
       "3         TP   1.000000  0.266667  \n",
       "4         TP   1.000000  0.312500  \n",
       "..       ...        ...       ...  \n",
       "338       FN   0.701863  0.953586  \n",
       "339       FP   0.699690  0.953586  \n",
       "340       FN   0.699690  0.953586  \n",
       "341       TN   0.699690  0.953586  \n",
       "342       FP   0.697531  0.953586  \n",
       "\n",
       "[343 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3917a178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Precision')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(final_df_sort['recall'], final_df_sort['precision'])\n",
    "plt.title('Precision vs Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c2ff7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8588, dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e831921b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\endo\\\\Desktop\\\\Yolov7-training-main\\\\Yolov7-training-main\\\\examples'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b556892b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>tp_fp_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>226376</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227132</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226372</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226653</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>227279</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>226973</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>226863</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>226614</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>243879</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>226720</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id tp_fp_fn\n",
       "0      226376       TP\n",
       "1      227132       TP\n",
       "2      226372       TP\n",
       "3      226653       TP\n",
       "4      227279       TP\n",
       "..        ...      ...\n",
       "338    226973       FN\n",
       "339    226863       FP\n",
       "340    226614       FN\n",
       "341    243879       TN\n",
       "342    226720       FP\n",
       "\n",
       "[343 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_sort[['image_id', 'tp_fp_fn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "316206c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = len(final_df_sort[final_df_sort['tp_fp_fn'] == 'TP'])\n",
    "FP = len(final_df_sort[final_df_sort['tp_fp_fn'] == 'FP'])\n",
    "FN = len(final_df_sort[final_df_sort['tp_fp_fn'] == 'FN'])\n",
    "TN = len(final_df_sort[final_df_sort['tp_fp_fn'] == 'TN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5288f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226,  98],\n",
       "       [ 11,   8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6cf93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb939c88",
   "metadata": {},
   "source": [
    "## mAP using: COCOMeanAveragePrecision() object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fa5a16e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m      9\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# # Assuming you have loaded the test dataset and the trained model\n",
    "# test_loader = ...\n",
    "# model = ...\n",
    "\n",
    "# # Evaluate the model on the test data\n",
    "# predictions = []\n",
    "# targets = []\n",
    "# for batch in test_loader:\n",
    "#     inputs = batch[\"image\"]\n",
    "#     targets.append(batch[\"targets\"])\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(inputs)\n",
    "#     predictions.append(outputs)\n",
    "\n",
    "# # Concatenate the predictions and targets\n",
    "# predictions = torch.cat(predictions)\n",
    "# targets = torch.cat(targets)\n",
    "\n",
    "# # Convert the predictions and targets to dataframes\n",
    "# preds_df = pd.DataFrame(\n",
    "#     predictions.cpu().numpy(),\n",
    "#     columns=[\n",
    "#         \"xmin\",\n",
    "#         \"ymin\",\n",
    "#         \"xmax\",\n",
    "#         \"ymax\",\n",
    "#         \"score\",\n",
    "#         \"class_id\",\n",
    "#         \"image_id\",\n",
    "#     ],\n",
    "# )\n",
    "# targets_df = pd.DataFrame(\n",
    "#     targets.cpu().numpy(),\n",
    "#     columns=[\"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class_id\"],\n",
    "# )\n",
    "\n",
    "# # Compute the mAP using COCOMeanAveragePrecision\n",
    "# evaluator = COCOMeanAveragePrecision()\n",
    "# map_ = evaluator.compute(targets_df, preds_df)\n",
    "\n",
    "# print(f\"mAP: {map_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7_custon",
   "language": "python",
   "name": "yolov7_custon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
